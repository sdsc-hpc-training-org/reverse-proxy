#!/bin/bash

## Authors: Developed by James McDougall [Github JamesMcDougallJr], Scott Sakai, 
## and Mary Thomas. The goal of this script is to start a jupyter notebook on various 
## HPC Systems by using the Reverse Proxy service. This makes a secure connection 
## between the user's local machine and the RP server.

## ====================================================================================
## Usage
##  ./start-jupyter [-p <string>] [-d <string>] [-b <string>] [-t <number>] [-s <jupyerlab, notebook>] [-i <string:image>] [-I]
##
##      -p: The partition your job will be started on. This can be either compute or
##          debug. Reminder that the debug queue has a max time of 30 minutes.
##
##      -d: The top level directory for your jupyter notebook. 
##          Default: /home/$USER 
##
##      -A: The Allocation (project) your notebook will be "charged" to. 
##          Default: the same as your system default. This is different for every user, 
##          but you can see your accounts using the `show_accounts` command.
##
##      -b: The batch script you want to submit. Of course the batch script needs to
##          start a jupyter notebook otherwise this script will fail. Cannot be used
##          simultaneously with the -s flag. 
##          Default: ./batch/batch_notebook.sh
##
##      -t: The time in MINTUES that you want the jupyter notebook to run for.
##          Default: 30 minutes
##
##      -s: The server to run for the user, can be 'notebook' for jupyter notebook or 
##          'jupyterlab' for jupyterlab. Cannot be used simultaneously with the -b flag.
##
##      -g: When using gpu-shared partitions, the number of gpus to use (0-3).
##
##      -i: print the environment variables along with submission. 
##
## =====================================================================================
source $PWD/lib/check_available.sh
source $PWD/lib/parse_time.sh
source $PWD/lib/jup_cleanup.sh
source $PWD/lib/remove_old_files.sh
source $PWD/lib/read_config.sh
source $PWD/lib/make_jupyter_config.sh

quiet=0
info=0
force=0
env=""
gpus=""
jup_root_dir="/home/$USER"
runtime="00:30:00"
project=""
env_path=""
server="notebook"
jup_msg="Jupyter not installed. To learn how to install Jupyter using Miniconda, check out this link: https://comet-notebooks-101.readthedocs.io/en/comet/prerequisites.html"

## Example Config
#Host Comet:
#  hostname: comet-*
#  endpoint: comet-user-content.sdsc.edu
#  system: slurm
#  default-partition: compute
#  batch-dir: slurm

vars=($(read_config $(hostname -s)))
export endpoint="${vars[1]}"
manager="${vars[2]}"
partition="${vars[3]}"
batch_dir="${vars[4]}"
[[ $endpoint =~ expanse-* ]] && require_account=1 || require_account=0

# Its not recommended that you change anything in this function.
function start-jupyter () {
    cluster=$(echo $endpoint | sed 's/-.*//')
    if [[ $gpus = "" ]]; then
	gpus=""
    elif [[ $cluster = "expanse" ]]; then
        gpus="--gpus=$gpus"
    else
        gpus="--gres=gpu:$gpus"
    fi
    # get the Reverse proxy API_TOKEN
    response="$(curl -s -w %{http_code} https://manage.$endpoint/getlink.cgi -o -)"
    status="$(echo $response | awk '{print $NF}')"
    if [[ $status != 200 ]]; then
        echo "Error connecting to reverse proxy: $status" 
        echo $response
        exit 1
    fi
    if [[ $response == Oops!* ]]; then
        echo $response 
        exit 1
    fi
    export api_token="$(echo $response | awk 'NF>1{printf $((NF-1))}' -)"
    check_available jupyter "'$jup_msg'" || exit 1

    # ensure the jupyter config directory exists and is accessible.
    # make a temp file there for the rps to read tokens
    jup_conf_dir="$(jupyter --config-dir)/rps"
    mkdir -p $jup_conf_dir || (echo "Failed to create dir $jup_conf_dir" && exit 1)
    chmod 0700 $jup_conf_dir || (echo "Failed to change permissions for $jup_conf_dir" && exit 1)
    export config=`mktemp -p $jup_conf_dir tmp.XXXXXX.py` 

    if [[ $config = "" ]]; then
        echo "Failed to create config file" 
        exit 1
    fi

    # remove old tmp files in this dir if still there
    remove_old_files $jup_conf_dir 10

    # Make a random ssl token
    export jupyter_token="$(openssl rand -hex 16)"
    make_jupyter_config $config $jupyter_token $jup_root_dir

    # Give the user their url
    export jupyter_url="https://$api_token.$endpoint?token=$jupyter_token"
    [[ $quiet = 0 ]] && echo "Your notebook is here:"
    [[ $quiet = 0 ]] && echo -e "\t$jupyter_url" || echo "$jupyter_url"
    [[ $quiet = 0 ]] && echo "If you encounter any issues, please email help@xsede.org and mention the Reverse Proxy Service."

    export start_root="$PWD"

    if [[ $server != "notebook" && $server != "jupyterlab" ]]; then
        echo Chose an invalid server. Choices are 'notebook' or 'jupyterlab'
        usage
        exit 1
    fi
    
    if [[ $script = "" ]]; then
        script=./$batch_dir/"$server".sh
        [[ $queit = 0 ]] && echo "Using $script"
    fi

    if [[ $info -eq 1 ]]; then
        echo "******************Start notebook info**********************" 
        echo "User $USER"
        echo "On cluster $cluster"
        echo "Using project $project" 
        echo "Batch Script: $script"
        echo "Partition: $partition"
        echo "Tempfile: $config"
        echo "Api token: $api_token"
        echo "Jupyter token: $jupyter_token"
        echo "Runtime: $runtime"
    	echo "Quiet: $QUIET"
        echo "GPUS: $gpus"
        echo "***********************************************************"
    fi

    # if sbatch is available, submit a job using that.
    if [[ $manager = "slurm" ]]; then
        if [[ $force = 1 ]]; then
            sbr="$(sbatch $script)" 
	elif [[ $project = "" ]]; then
            sbr="$(sbatch -t $runtime -p $partition $gpus "$script")"
        else
            sbr="$(sbatch -t $runtime -A $project -p $partition $gpus "$script")"
        fi  
        if [[ $sbr =~ Submitted\ batch\ job\ ([0-9]+) ]]; then
            slurm_id=${BASH_REMATCH[1]}
            [[ $quiet = 0 ]] && echo Your job id is $slurm_id
            [[ $quiet = 0 ]] && echo "You may occasionally run the command 'squeue -j $slurm_id' to check the status of your job"
            cleanup_slurm $slurm_id $config &
            exit 0
        else
            echo "Sbatch failed"
            exit 1
        fi
    elif [[ $manager = "torque" ]]; then
	qout=$(qsub -l walltime=${runtime#-t **} -q $partition $script)
        if [[ "$qout" =~ [0-9]+.tscc-mgr[0-9].local ]]; then
            qid=$(echo "${BASH_REMATCH[@]}" | sed 's/[^0-9]*//g')
	    qid="${qid:0:${#qid}-1}"
            [[ $quiet = 0 ]] && echo "Your job id is $qid"
	    [[ $quiet = 0 ]] && echo "You may occasionally run the command 'qstat $qid' to check the status of your job"
            exit 0
        else
            echo "Torque failed"
            exit 1
        fi
    else
        echo "No queue system found. Please use slurm or torque"
    fi
}

usage() { 
    echo "Usage: $0 [-p <string>] [-d <string>] [-A <string>] [-b <string>] [-t time] [-s 'notebook' | 'jupyterlab'] [-i <string>] [-I]" 1>&2;
    echo -e "-p: the partition to use, debug or compute. Default is compute" 1>&2;
    echo -e "-d: the top-level directory of your jupyter notebook. Default is /home/$USER" 1>&2;
    echo -e "-A: the project allocation to be used for this notebook. Default is system default (also called project or group)" 1>&2;
    echo -e "-b: the batch script you want to submit. Only those in the batch folder are supported. Default is ./batch/batch_notebook.sh" 1>&2;
    echo -e "-s: Choose between 'notebook' and 'jupyterlab'" 1>&2;
    echo -e "-g: Number of gpus to use for gpu shared partitions" 1>&2;
    echo -e "-i: Choose a singularity container to start your notebook in." 1>&2;
    echo -e "-I: Get extra information about the job you submitted using the script" 1>&2;
}

# Transform long options to short ones
for arg in "$@"; do
  shift
  case "$arg" in
    "--help")          set -- "$@" "-h" ;;
    "--quiet")         set -- "$@" "-q" ;;
    "--local")         set -- "$@" "-x" ;;
    "--conda")         set -- "$@" "-y" ;;
    "--singularity")   set -- "$@" "-z" ;;
    *)                 set -- "$@" "$arg"
  esac
done

# Parse short options
OPTIND=1
err=0
sb_conflict=0
while [ $OPTIND -le "$#" ]
do
    if getopts "h?:d:A:g:s:p:b:t:y:z:fiqx" opt; then
        case "$opt" in
            h|\?) usage 
                  exit 0 ;;
            g)  gpus="$OPTARG";;
            s)  server="$OPTARG"
                sb_conflict="$((sb_conflict+1))" ;;
            d)  jup_root_dir="$OPTARG";;
            A)  project="$OPTARG" ;;
            p)  partition="$OPTARG" ;;
            b)  script="$OPTARG"
                sb_conflict="$((sb_conflict+1))" ;;
            t)  runtime="$(parse_time $OPTARG)" ;;
            x)  export env="local";;
            y)  export env="conda"
                export env_path="$OPTARG";;
            z)  export env="singularity"
                export env_path="$OPTARG";;
            f)  force=1 ;;
            q)  quiet=1 ;;
            i)  info=1;;
            *)  echo "Error: invalid optional argument $OPTARG" 
                err=1
                ;;
        esac
    else
        pos_args=1
        err=1
        ((OPTIND++))
    fi
done
shift $(expr $OPTIND - 1) # remove options from positional parameters

if [[ $pos_args ]]; then
    echo "Encountered positional arguments where none are required."
fi

# if there is a conflict between the -s and -b flags
if [[ $sb_conflict = 2 ]]; then
    echo "You cannot use the -s flag and the -b flag simultaneously" 
    err=1
fi

if [[ ${partition##* } = "debug" && ${runtime##* } > 30 ]]; then
    echo "Invalid runtime for debug queue. Must be less than or equal to 30 minutes"
    err=1
fi

if [[ $project = "" && $require_account = 1 ]]; then
    echo "Expanse requries you to explicitly specify your account. Please provide the -A <Account> argument"
    err=1
fi

if [[ $err = 1 ]]; then
    usage 
    exit 1
fi

start-jupyter
